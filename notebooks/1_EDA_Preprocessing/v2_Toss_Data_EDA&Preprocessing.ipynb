{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b490cef2-18e9-4053-9e94-41da91e7b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR - Preprocessing v2_final_light\n",
    "# (ì»¤ë„ ì•ˆì •í™” ë²„ì „)\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a292e08-9710-4cd9-98a9-b98c0fa47c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (10704179, 119) | Test: (1527298, 119)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pyarrow ì—”ì§„ ê³ ì • (ë²„ì „ ì¶©ëŒ ë°©ì§€)\n",
    "pd.options.io.parquet.engine = \"pyarrow\"\n",
    "\n",
    "train = pd.read_parquet(\"train.parquet\")\n",
    "test  = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "print(\"Train:\", train.shape, \"| Test:\", test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb2327a-06f6-46eb-832e-22a89c9d94d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] ì™„ì „ ì¤‘ë³µ 11ê±´ ì œê±° ì¤‘...\n",
      "[done] ì¤‘ë³µ ì œê±° í›„: (10704168, 119)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# -----------------------------------------------\n",
    "# 2. ì™„ì „ ì¤‘ë³µ ì œê±° (í–‰ ì „ì²´ ë™ì¼í•œ ê²½ìš°ë§Œ)\n",
    "# -----------------------------------------------\n",
    "dup_count = train.duplicated().sum()\n",
    "if dup_count > 0:\n",
    "    print(f\"[info] ì™„ì „ ì¤‘ë³µ {dup_count}ê±´ ì œê±° ì¤‘...\")\n",
    "    train = train.drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"[done] ì¤‘ë³µ ì œê±° í›„: {train.shape}\")\n",
    "else:\n",
    "    print(\"[info] ì™„ì „ ì¤‘ë³µ ì—†ìŒ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a76944-2a74-4383-8af5-d6538b81134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 3. feat_e_3 ê²°ì¸¡ ì²˜ë¦¬ (age_groupë³„ ì¤‘ì•™ê°’ â†’ global median)\n",
    "# -----------------------------------------------\n",
    "train[\"feat_e_3_isna\"] = train[\"feat_e_3\"].isnull().astype(int)\n",
    "test[\"feat_e_3_isna\"]  = test[\"feat_e_3\"].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb95ab1-c262-4f91-8cdc-4fc6e2485fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ì•™ê°’ ë§¤í•‘ (ë²¡í„°í™” ë²„ì „, ì•ˆì „í•˜ê³  ë¹ ë¦„)\n",
    "age_median = train.groupby(\"age_group\")[\"feat_e_3\"].median()\n",
    "train[\"feat_e_3\"] = train[\"feat_e_3\"].fillna(train[\"age_group\"].map(age_median))\n",
    "test[\"feat_e_3\"]  = test[\"feat_e_3\"].fillna(test[\"age_group\"].map(age_median))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664d20d9-593b-4b80-ace9-4d2f39ef0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global medianìœ¼ë¡œ ìµœì¢… ë³´ì™„\n",
    "global_median = train[\"feat_e_3\"].median()\n",
    "train[\"feat_e_3\"] = train[\"feat_e_3\"].fillna(global_median)\n",
    "test[\"feat_e_3\"]  = test[\"feat_e_3\"].fillna(global_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5eeb629-50c7-4bce-ba46-8bfc27ed2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 4. Sequence feature ìƒì„±\n",
    "# -----------------------------------------------\n",
    "train[\"seq_length\"] = train[\"seq\"].astype(str).apply(lambda x: len(x.split(\",\")))\n",
    "test[\"seq_length\"]  = test[\"seq\"].astype(str).apply(lambda x: len(x.split(\",\")))\n",
    "\n",
    "train[\"seq_length_log\"] = np.log1p(train[\"seq_length\"])\n",
    "test[\"seq_length_log\"]  = np.log1p(test[\"seq_length\"])\n",
    "\n",
    "if \"seq\" in train.columns:\n",
    "    def count_unique_items(seq_str):\n",
    "        try:\n",
    "            items = str(seq_str).split(',')\n",
    "            return len(set(items))\n",
    "        except:\n",
    "            return 0\n",
    "            \n",
    "train[\"unique_items\"] = train[\"seq\"].apply(count_unique_items)\n",
    "test[\"unique_items\"]  = test[\"seq\"].apply(count_unique_items)\n",
    "\n",
    "train[\"diversity_ratio\"] = train[\"unique_items\"] / train[\"seq_length\"].replace(0, np.nan)\n",
    "test[\"diversity_ratio\"]  = test[\"unique_items\"] / test[\"seq_length\"].replace(0, np.nan)\n",
    "\n",
    "# 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ í›„ ê²°ì¸¡ ë³´ì™„\n",
    "train[\"diversity_ratio\"] = train[\"diversity_ratio\"].fillna(0)\n",
    "test[\"diversity_ratio\"]  = test[\"diversity_ratio\"].fillna(0)\n",
    "    \n",
    "# ë©”ëª¨ë¦¬ ì ˆì•½ìš©: seq ì œê±°\n",
    "train = train.drop(columns=[\"seq\"], errors=\"ignore\")\n",
    "test  = test.drop(columns=[\"seq\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db1bbf7-a4ad-4b4c-917c-e812921065e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒˆ [CHECK] diversity_ratio ìƒì„± ì™„ë£Œ\n",
      "  train shape: (10704168, 123), test shape: (1527298, 123)\n",
      "  train diversity_ratio null ë¹„ìœ¨: 0.0000\n",
      "  test  diversity_ratio null ë¹„ìœ¨: 0.0000\n",
      "  train diversity_ratio ìƒ˜í”Œ: [0.07269155206286837, 0.1128747795414462, 0.07445255474452554]\n",
      "  test  diversity_ratio ìƒ˜í”Œ: [0.1282952548330404, 0.15083798882681565, 0.29245283018867924]\n"
     ]
    }
   ],
   "source": [
    "if \"diversity_ratio\" not in train.columns:\n",
    "    raise RuntimeError(\"âŒ [ERROR] diversity_ratio ìƒì„± ì‹¤íŒ¨: trainì— ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "if \"diversity_ratio\" not in test.columns:\n",
    "    raise RuntimeError(\"âŒ [ERROR] diversity_ratio ìƒì„± ì‹¤íŒ¨: testì— ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ê°’ ê²€ì¦ (ìš”ì•½ í†µê³„)\n",
    "print(\"\\nğŸŒˆ [CHECK] diversity_ratio ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"  train shape: {train.shape}, test shape: {test.shape}\")\n",
    "print(f\"  train diversity_ratio null ë¹„ìœ¨: {train['diversity_ratio'].isna().mean():.4f}\")\n",
    "print(f\"  test  diversity_ratio null ë¹„ìœ¨: {test['diversity_ratio'].isna().mean():.4f}\")\n",
    "print(f\"  train diversity_ratio ìƒ˜í”Œ: {train['diversity_ratio'].head(3).tolist()}\")\n",
    "print(f\"  test  diversity_ratio ìƒ˜í”Œ: {test['diversity_ratio'].head(3).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55676e63-6a3d-4289-9c5b-2810d0c7eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_feats = [\"history_mean\", \"history_var\", \"seq_length\"]\n",
    "cluster_feats = [c for c in cluster_feats if c in train.columns]\n",
    "if len(cluster_feats) >= 2:\n",
    "    km = KMeans(n_clusters=10, random_state=42)\n",
    "    train[\"user_cluster\"] = km.fit_predict(train[cluster_feats])\n",
    "    test[\"user_cluster\"]  = km.predict(test[cluster_feats])\n",
    "else:\n",
    "    train[\"user_cluster\"] = 0\n",
    "    test[\"user_cluster\"]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc4b2cca-fac2-48d0-8c1f-5d8e73ff8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 5. History feature ìƒì„± (history_a_1 / b_2 ìœ ì§€)\n",
    "# -----------------------------------------------\n",
    "if \"user_id\" in train.columns:\n",
    "    # user_id dtypeì„ categoryë¡œ ë³€í™˜\n",
    "    train[\"user_id\"] = train[\"user_id\"].astype(\"category\")\n",
    "    test[\"user_id\"]  = test[\"user_id\"].astype(\"category\")\n",
    "\n",
    "    user_stats = (\n",
    "        train.groupby(\"user_id\")[\"clicked\"]\n",
    "        .agg(history_mean=\"mean\", history_var=\"var\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    train = train.merge(user_stats, on=\"user_id\", how=\"left\")\n",
    "    test  = test.merge(user_stats, on=\"user_id\", how=\"left\")\n",
    "else:\n",
    "    train[\"history_mean\"] = 0\n",
    "    train[\"history_var\"]  = 0\n",
    "    test[\"history_mean\"]  = 0\n",
    "    test[\"history_var\"]   = 0\n",
    "\n",
    "hist_a_cols = [c for c in train.columns if \"history_a_\" in c]\n",
    "hist_b_cols = [c for c in train.columns if \"history_b_\" in c]\n",
    "\n",
    "train[\"history_a_mean\"] = train[hist_a_cols].mean(axis=1) if len(hist_a_cols) > 0 else 0\n",
    "test[\"history_a_mean\"]  = test[hist_a_cols].mean(axis=1)  if len(hist_a_cols) > 0 else 0\n",
    "\n",
    "train[\"history_b_mean\"] = train[hist_b_cols].mean(axis=1) if len(hist_b_cols) > 0 else 0\n",
    "test[\"history_b_mean\"]  = test[hist_b_cols].mean(axis=1)  if len(hist_b_cols) > 0 else 0\n",
    "\n",
    "for col in [\"history_a_1\", \"history_b_2\"]:\n",
    "    if col not in train.columns:\n",
    "        train[col] = 0\n",
    "        test[col]  = 0\n",
    "\n",
    "# corr() ê³„ì‚° ì œê±° (heavy ì—°ì‚° ë°©ì§€)\n",
    "train[\"history_clicked_corr\"] = 0\n",
    "test[\"history_clicked_corr\"]  = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3668a36b-04dc-487c-9aa3-6cb80c346238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 6. flag feature (íƒ€ì… ì•ˆì •í™” + ì•ˆì „ëª¨ë“œ)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# hour â†’ ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ë¬¸ìì—´ì´ë©´ NaN ì²˜ë¦¬)\n",
    "if \"hour\" in train.columns:\n",
    "    train[\"hour\"] = pd.to_numeric(train[\"hour\"], errors=\"coerce\")\n",
    "    test[\"hour\"]  = pd.to_numeric(test[\"hour\"], errors=\"coerce\")\n",
    "\n",
    "    train[\"night_flag\"] = train[\"hour\"].between(0, 6, inclusive=\"both\").astype(int)\n",
    "    test[\"night_flag\"]  = test[\"hour\"].between(0, 6, inclusive=\"both\").astype(int)\n",
    "\n",
    "# day_of_week â†’ ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜\n",
    "if \"day_of_week\" in train.columns:\n",
    "    train[\"day_of_week\"] = pd.to_numeric(train[\"day_of_week\"], errors=\"coerce\")\n",
    "    test[\"day_of_week\"]  = pd.to_numeric(test[\"day_of_week\"], errors=\"coerce\")\n",
    "\n",
    "    train[\"is_weekend\"]  = train[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    test[\"is_weekend\"]   = test[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    train[\"tuesday_flag\"] = (train[\"day_of_week\"] == 1).astype(int)\n",
    "    test[\"tuesday_flag\"]  = (test[\"day_of_week\"] == 1).astype(int)\n",
    "\n",
    "# user_id ê¸°ë°˜ ì‹ ê·œ ìœ ì € í”Œë˜ê·¸\n",
    "if \"user_id\" in train.columns:\n",
    "    # category dtypeì´ë©´ set ë³€í™˜ í›¨ì”¬ ê°€ë²¼ì›€\n",
    "    seen_users = set(train[\"user_id\"].astype(str))\n",
    "    test[\"new_user_flag\"] = (~test[\"user_id\"].astype(str).isin(seen_users)).astype(int)\n",
    "    train[\"new_user_flag\"] = 0\n",
    "else:\n",
    "    train[\"new_user_flag\"] = 0\n",
    "    test[\"new_user_flag\"]  = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "477580d6-f56f-463c-be59-c465cfc8a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ í•„ìˆ˜ í”¼ì²˜ ì¡´ì¬ ì—¬ë¶€:\n",
      "seq_length: âœ…\n",
      "seq_length_log: âœ…\n",
      "history_mean: âœ…\n",
      "history_var: âœ…\n",
      "history_a_mean: âœ…\n",
      "history_b_mean: âœ…\n",
      "history_a_1: âœ…\n",
      "history_b_2: âœ…\n",
      "history_clicked_corr: âœ…\n",
      "feat_e_3: âœ…\n",
      "feat_e_3_isna: âœ…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 7. Category ìµœì†Œí™”\n",
    "# -----------------------------------------------\n",
    "for col in [\"gender\", \"age_group\", \"inventory_id\"]:\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].astype(\"category\")\n",
    "        test[col]  = test[col].astype(\"category\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 8. ì£¼ìš” í”¼ì²˜ ê²€ì¦ (print ìµœì†Œí™”)\n",
    "# -----------------------------------------------\n",
    "must_have = [\n",
    "    \"seq_length\", \"seq_length_log\", \"history_mean\", \"history_var\",\n",
    "    \"history_a_mean\", \"history_b_mean\", \"history_a_1\", \"history_b_2\",\n",
    "    \"history_clicked_corr\", \"feat_e_3\", \"feat_e_3_isna\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“‹ í•„ìˆ˜ í”¼ì²˜ ì¡´ì¬ ì—¬ë¶€:\")\n",
    "for col in must_have:\n",
    "    print(f\"{col}: {'âœ…' if col in train.columns else 'âŒ'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ca09ab6-97bc-45d8-91c8-6aaa3e32bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: train_basic_2.parquet / test_basic_2.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 9. ì €ì¥ (snappy ì••ì¶•)\n",
    "# -----------------------------------------------\n",
    "train.to_parquet(\"train_basic_2.parquet\", index=False, compression=\"snappy\")\n",
    "test.to_parquet(\"test_basic_2.parquet\", index=False, compression=\"snappy\")\n",
    "\n",
    "print(\"âœ… ì €ì¥ ì™„ë£Œ: train_basic_2.parquet / test_basic_2.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02afc81-7598-4c81-ab2c-3800d5308ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
