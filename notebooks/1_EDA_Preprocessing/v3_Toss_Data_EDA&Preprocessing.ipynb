{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27762f7e-5e5d-4e85-8567-65a8e701880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR - Preprocessing v3 (Leakage-Free + ID/Target Preserved)\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.options.io.parquet.engine = \"pyarrow\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f666e892-3185-4dce-bfcc-b5e63ac377fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (10704179, 119) | Test: (1527298, 119)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 1. Load\n",
    "# -----------------------------------------------\n",
    "train = pd.read_parquet(\"train.parquet\")\n",
    "test  = pd.read_parquet(\"test.parquet\")\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb36706-66ae-4b42-8af9-d4db7689eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 'row_id' as ID column, target = clicked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2735225/4228069958.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"feat_e_3\"].fillna(global_median, inplace=True)\n",
      "/tmp/ipykernel_2735225/4228069958.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"feat_e_3\"].fillna(global_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 2. ID / Target 보존\n",
    "# -----------------------------------------------\n",
    "if \"ID\" in test.columns:\n",
    "    test.rename(columns={\"ID\": \"id\"}, inplace=True)\n",
    "\n",
    "if \"id\" not in train.columns:\n",
    "    train[\"row_id\"] = np.arange(len(train))\n",
    "    id_col = \"row_id\"\n",
    "else:\n",
    "    id_col = \"id\"\n",
    "\n",
    "target_col = \"clicked\" if \"clicked\" in train.columns else None\n",
    "print(f\"[info] Using '{id_col}' as ID column, target = {target_col}\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3. 완전 중복 제거\n",
    "# -----------------------------------------------\n",
    "dup_count = train.duplicated().sum()\n",
    "if dup_count > 0:\n",
    "    print(f\"[info] 완전 중복 {dup_count}건 제거\")\n",
    "    train = train.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4. feat_e_3 결측 처리\n",
    "# -----------------------------------------------\n",
    "train[\"feat_e_3_isna\"] = train[\"feat_e_3\"].isnull().astype(int)\n",
    "test[\"feat_e_3_isna\"]  = test[\"feat_e_3\"].isnull().astype(int)\n",
    "\n",
    "age_median = train.groupby(\"age_group\")[\"feat_e_3\"].median()\n",
    "train[\"feat_e_3\"] = train[\"feat_e_3\"].fillna(train[\"age_group\"].map(age_median))\n",
    "test[\"feat_e_3\"]  = test[\"feat_e_3\"].fillna(test[\"age_group\"].map(age_median))\n",
    "\n",
    "global_median = train[\"feat_e_3\"].median()\n",
    "train[\"feat_e_3\"].fillna(global_median, inplace=True)\n",
    "test[\"feat_e_3\"].fillna(global_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb4f758-e8ae-420a-b360-92eec8a4e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2735225/355703751.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"diversity_ratio\"].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_2735225/355703751.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"diversity_ratio\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 5. Sequence Feature\n",
    "# -----------------------------------------------\n",
    "def count_unique_items(seq_str):\n",
    "    try:\n",
    "        items = str(seq_str).split(',')\n",
    "        return len(set(items))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "train[\"seq_length\"] = train[\"seq\"].astype(str).apply(lambda x: len(x.split(\",\")))\n",
    "test[\"seq_length\"]  = test[\"seq\"].astype(str).apply(lambda x: len(x.split(\",\")))\n",
    "train[\"seq_length_log\"] = np.log1p(train[\"seq_length\"])\n",
    "test[\"seq_length_log\"]  = np.log1p(test[\"seq_length\"])\n",
    "\n",
    "train[\"unique_items\"] = train[\"seq\"].apply(count_unique_items)\n",
    "test[\"unique_items\"]  = test[\"seq\"].apply(count_unique_items)\n",
    "train[\"diversity_ratio\"] = train[\"unique_items\"] / train[\"seq_length\"].replace(0, np.nan)\n",
    "test[\"diversity_ratio\"]  = test[\"unique_items\"] / test[\"seq_length\"].replace(0, np.nan)\n",
    "train[\"diversity_ratio\"].fillna(0, inplace=True)\n",
    "test[\"diversity_ratio\"].fillna(0, inplace=True)\n",
    "\n",
    "train.drop(columns=[\"seq\"], errors=\"ignore\", inplace=True)\n",
    "test.drop(columns=[\"seq\"], errors=\"ignore\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c644dc4-af42-4da5-b45c-19afedb8523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 6. user_cluster (lightweight KMeans)\n",
    "# -----------------------------------------------\n",
    "cluster_feats = [\"history_mean\", \"history_var\", \"seq_length\"]\n",
    "cluster_feats = [c for c in cluster_feats if c in train.columns]\n",
    "if len(cluster_feats) >= 2:\n",
    "    km = KMeans(n_clusters=10, random_state=42)\n",
    "    train[\"user_cluster\"] = km.fit_predict(train[cluster_feats])\n",
    "    test[\"user_cluster\"]  = km.predict(test[cluster_feats])\n",
    "else:\n",
    "    train[\"user_cluster\"] = 0\n",
    "    test[\"user_cluster\"]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de7012b-0558-4d45-9a0f-a36ecd109298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Generating leakage-free history features...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 7. history_mean / var (Leakage-free OOF version)\n",
    "# -----------------------------------------------\n",
    "print(\"[info] Generating leakage-free history features...\")\n",
    "if \"user_id\" in train.columns:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train[\"history_mean\"] = np.nan\n",
    "    train[\"history_var\"]  = np.nan\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        tr_sub = train.iloc[tr_idx]\n",
    "        val_sub = train.iloc[val_idx]\n",
    "        stats = (\n",
    "            tr_sub.groupby(\"user_id\")[\"clicked\"]\n",
    "            .agg(history_mean=\"mean\", history_var=\"var\")\n",
    "        )\n",
    "        train.loc[val_idx, \"history_mean\"] = val_sub[\"user_id\"].map(stats[\"history_mean\"])\n",
    "        train.loc[val_idx, \"history_var\"]  = val_sub[\"user_id\"].map(stats[\"history_var\"])\n",
    "\n",
    "    # test는 전체 train 통계로 계산\n",
    "    full_stats = (\n",
    "        train.groupby(\"user_id\")[\"clicked\"]\n",
    "        .agg(history_mean=\"mean\", history_var=\"var\")\n",
    "    )\n",
    "    test[\"history_mean\"] = test[\"user_id\"].map(full_stats[\"history_mean\"])\n",
    "    test[\"history_var\"]  = test[\"user_id\"].map(full_stats[\"history_var\"])\n",
    "\n",
    "    # 결측치 (신규 유저)\n",
    "    global_mean = train[\"clicked\"].mean()\n",
    "    global_var  = train[\"clicked\"].var()\n",
    "    train[\"history_mean\"].fillna(global_mean, inplace=True)\n",
    "    train[\"history_var\"].fillna(global_var, inplace=True)\n",
    "    test[\"history_mean\"].fillna(global_mean, inplace=True)\n",
    "    test[\"history_var\"].fillna(global_var, inplace=True)\n",
    "else:\n",
    "    train[\"history_mean\"] = 0\n",
    "    train[\"history_var\"]  = 0\n",
    "    test[\"history_mean\"]  = 0\n",
    "    test[\"history_var\"]   = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6ba123-c61e-4ff8-8a59-1d3d191caf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 8. history_a/b mean\n",
    "# -----------------------------------------------\n",
    "hist_a_cols = [c for c in train.columns if \"history_a_\" in c]\n",
    "hist_b_cols = [c for c in train.columns if \"history_b_\" in c]\n",
    "train[\"history_a_mean\"] = train[hist_a_cols].mean(axis=1) if len(hist_a_cols) > 0 else 0\n",
    "test[\"history_a_mean\"]  = test[hist_a_cols].mean(axis=1)  if len(hist_a_cols) > 0 else 0\n",
    "train[\"history_b_mean\"] = train[hist_b_cols].mean(axis=1) if len(hist_b_cols) > 0 else 0\n",
    "test[\"history_b_mean\"]  = test[hist_b_cols].mean(axis=1)  if len(hist_b_cols) > 0 else 0\n",
    "for col in [\"history_a_1\", \"history_b_2\"]:\n",
    "    if col not in train.columns:\n",
    "        train[col] = 0\n",
    "        test[col]  = 0\n",
    "train[\"history_clicked_corr\"] = 0\n",
    "test[\"history_clicked_corr\"]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9850e43b-b5b0-4987-b182-09598dde5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 9. Flags\n",
    "# -----------------------------------------------\n",
    "if \"hour\" in train.columns:\n",
    "    train[\"hour\"] = pd.to_numeric(train[\"hour\"], errors=\"coerce\")\n",
    "    test[\"hour\"]  = pd.to_numeric(test[\"hour\"], errors=\"coerce\")\n",
    "    train[\"night_flag\"] = train[\"hour\"].between(0, 6, inclusive=\"both\").astype(int)\n",
    "    test[\"night_flag\"]  = test[\"hour\"].between(0, 6, inclusive=\"both\").astype(int)\n",
    "\n",
    "if \"day_of_week\" in train.columns:\n",
    "    train[\"day_of_week\"] = pd.to_numeric(train[\"day_of_week\"], errors=\"coerce\")\n",
    "    test[\"day_of_week\"]  = pd.to_numeric(test[\"day_of_week\"], errors=\"coerce\")\n",
    "    train[\"is_weekend\"]  = train[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    test[\"is_weekend\"]   = test[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    train[\"tuesday_flag\"] = (train[\"day_of_week\"] == 1).astype(int)\n",
    "    test[\"tuesday_flag\"]  = (test[\"day_of_week\"] == 1).astype(int)\n",
    "\n",
    "# 신규 유저 flag\n",
    "if \"user_id\" in train.columns:\n",
    "    seen_users = set(train[\"user_id\"].astype(str))\n",
    "    test[\"new_user_flag\"] = (~test[\"user_id\"].astype(str).isin(seen_users)).astype(int)\n",
    "    train[\"new_user_flag\"] = 0\n",
    "else:\n",
    "    train[\"new_user_flag\"] = 0\n",
    "    test[\"new_user_flag\"]  = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab2d5c4-c984-4397-b93d-7a98b5e5e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 10. Category dtype\n",
    "# -----------------------------------------------\n",
    "for col in [\"gender\", \"age_group\", \"inventory_id\"]:\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].astype(\"category\")\n",
    "        test[col]  = test[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1d61f3-9b6f-4c48-bef4-fef1ed3a480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved train_basic_3.parquet / test_basic_3.parquet (ID + clicked preserved)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 11. 저장 (ID + clicked 항상 보존)\n",
    "# -----------------------------------------------\n",
    "cols_to_keep = [id_col]\n",
    "if target_col is not None:\n",
    "    cols_to_keep.append(target_col)\n",
    "\n",
    "train = pd.concat([train[cols_to_keep], train.drop(columns=cols_to_keep)], axis=1)\n",
    "if id_col in test.columns:\n",
    "    test = pd.concat([test[[id_col]], test.drop(columns=[id_col])], axis=1)\n",
    "\n",
    "train.to_parquet(\"train_basic_3.parquet\", index=False, compression=\"snappy\")\n",
    "test.to_parquet(\"test_basic_3.parquet\", index=False, compression=\"snappy\")\n",
    "\n",
    "print(\"✅ Saved train_basic_3.parquet / test_basic_3.parquet (ID + clicked preserved)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92daefe-9c9c-4e43-9f53-6ca27fabbd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
