{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c844ca7-20b0-4541-b020-a2d24abfb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR - LGBM (v3 Hybrid Compatible)\n",
    "# CORE + TREE_OPT 전용 Feature 사용\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e99f8af-669f-447e-b011-3c1cc280c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Using 26 CORE + TREE_OPT features\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 1️⃣ Load data & feature groups\n",
    "# -----------------------------------------------\n",
    "train = pd.read_parquet(\"train_input_3.parquet\")\n",
    "test  = pd.read_parquet(\"test_input_3.parquet\")\n",
    "feat_grp = pd.read_csv(\"feature_groups.csv\")\n",
    "\n",
    "# group 필터링\n",
    "tree_features = feat_grp.query(\"group in ['CORE','TREE_OPT']\")[\"column\"].tolist()\n",
    "print(f\"[info] Using {len(tree_features)} CORE + TREE_OPT features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d472bc86-987c-4ea0-acc7-3f37c1c05e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2800824/1423711509.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[c] = X[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1423711509.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[c] = X_test[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1423711509.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[c] = X[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1423711509.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[c] = X_test[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1423711509.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[c] = X[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1423711509.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[c] = X_test[c].astype(\"category\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] 3 categorical features detected.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ID / target setup\n",
    "# -----------------------------------------------\n",
    "target_col = \"clicked\"\n",
    "id_col = \"id\"\n",
    "\n",
    "# feature subset\n",
    "X = train[tree_features]\n",
    "y = train[target_col]\n",
    "\n",
    "X_test = test[tree_features]\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2️⃣ dtype 정리 (LightGBM용 category 인식)\n",
    "# -----------------------------------------------\n",
    "cat_cols = X.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "print(f\"[info] {len(cat_cols)} categorical features detected.\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3️⃣ Train/Valid split\n",
    "# -----------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f7cba6-2a8b-4e4b-b2a9-b4eebdccac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] scale_pos_weight = 51.43\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 4️⃣ scale_pos_weight (Weighted LogLoss)\n",
    "# -----------------------------------------------\n",
    "pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "print(f\"[info] scale_pos_weight = {pos_weight:.2f}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, params={\"max_bin\": 512})\n",
    "val_data   = lgb.Dataset(X_val, label=y_val, params={\"max_bin\": 512})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cf0565-8478-4867-8267-1ebb8f4e61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 5️⃣ LightGBM Parameters\n",
    "# -----------------------------------------------\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 96,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"scale_pos_weight\": np.sqrt(pos_weight),\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "    \"n_jobs\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "callbacks = [lgb.log_evaluation(period=100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f626f976-d7a6-400f-92d7-b34684a7b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's binary_logloss: 0.150783\tvalid's binary_logloss: 0.151137\n",
      "[200]\ttrain's binary_logloss: 0.154375\tvalid's binary_logloss: 0.155034\n",
      "[300]\ttrain's binary_logloss: 0.154002\tvalid's binary_logloss: 0.154965\n",
      "[400]\ttrain's binary_logloss: 0.15353\tvalid's binary_logloss: 0.15479\n",
      "[500]\ttrain's binary_logloss: 0.153014\tvalid's binary_logloss: 0.154539\n",
      "[600]\ttrain's binary_logloss: 0.152538\tvalid's binary_logloss: 0.154347\n",
      "[700]\ttrain's binary_logloss: 0.15206\tvalid's binary_logloss: 0.154138\n",
      "[800]\ttrain's binary_logloss: 0.151603\tvalid's binary_logloss: 0.153943\n",
      "[900]\ttrain's binary_logloss: 0.151181\tvalid's binary_logloss: 0.153783\n",
      "[1000]\ttrain's binary_logloss: 0.150762\tvalid's binary_logloss: 0.153621\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 6️⃣ Train base model\n",
    "# -----------------------------------------------\n",
    "model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b6a93d-7902-4e18-abda-e79e54740c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Initially selected 13 features out of 26 total.\n",
      "[info] After removing highly correlated ones (>0.9): 12 remain.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 7️⃣ Feature Importance 기반 Selection\n",
    "# -----------------------------------------------\n",
    "imp = pd.DataFrame({\n",
    "    \"feature\": model.feature_name(),\n",
    "    \"importance\": model.feature_importance(importance_type=\"gain\")\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "imp[\"norm_imp\"] = imp[\"importance\"] / imp[\"importance\"].sum()\n",
    "imp[\"cum_ratio\"] = imp[\"norm_imp\"].cumsum()\n",
    "\n",
    "selected_features = imp.loc[imp[\"cum_ratio\"] <= 0.95, \"feature\"].tolist()\n",
    "print(f\"[info] Initially selected {len(selected_features)} features out of {X.shape[1]} total.\")\n",
    "\n",
    "# 상관관계 제거\n",
    "corr_matrix = X[selected_features].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "selected_features = [f for f in selected_features if f not in high_corr_features]\n",
    "print(f\"[info] After removing highly correlated ones (>0.9): {len(selected_features)} remain.\")\n",
    "\n",
    "imp.to_csv(\"feature_importance_v3_full.csv\", index=False)\n",
    "pd.Series(selected_features, name=\"selected_features_v3\").to_csv(\"selected_features_v3.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c64e16-2a4a-47ea-ab75-09f7c36b937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2800824/1259677173.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_sel[c] = X_train_sel[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1259677173.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_sel[c]   = X_val_sel[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1259677173.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_sel[c]  = X_test_sel[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1259677173.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_sel[c] = X_train_sel[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1259677173.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_sel[c]   = X_val_sel[c].astype(\"category\")\n",
      "/tmp/ipykernel_2800824/1259677173.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_sel[c]  = X_test_sel[c].astype(\"category\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[phase 2] Training model with selected features...\n",
      "[100]\ttrain's binary_logloss: 0.150865\tvalid's binary_logloss: 0.151233\n",
      "[200]\ttrain's binary_logloss: 0.154504\tvalid's binary_logloss: 0.155176\n",
      "[300]\ttrain's binary_logloss: 0.154152\tvalid's binary_logloss: 0.15512\n",
      "[400]\ttrain's binary_logloss: 0.153692\tvalid's binary_logloss: 0.154947\n",
      "[500]\ttrain's binary_logloss: 0.153188\tvalid's binary_logloss: 0.154708\n",
      "[600]\ttrain's binary_logloss: 0.15273\tvalid's binary_logloss: 0.154511\n",
      "[700]\ttrain's binary_logloss: 0.152277\tvalid's binary_logloss: 0.154313\n",
      "[800]\ttrain's binary_logloss: 0.151839\tvalid's binary_logloss: 0.154128\n",
      "[900]\ttrain's binary_logloss: 0.15144\tvalid's binary_logloss: 0.15397\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 8️⃣ Retrain with selected features\n",
    "# -----------------------------------------------\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_val_sel   = X_val[selected_features]\n",
    "X_test_sel  = X_test[selected_features]\n",
    "\n",
    "# dtype 유지 (category형 그대로)\n",
    "for c in cat_cols:\n",
    "    if c in X_train_sel.columns:\n",
    "        X_train_sel[c] = X_train_sel[c].astype(\"category\")\n",
    "        X_val_sel[c]   = X_val_sel[c].astype(\"category\")\n",
    "        X_test_sel[c]  = X_test_sel[c].astype(\"category\")\n",
    "\n",
    "train_data_sel = lgb.Dataset(X_train_sel, label=y_train, params={\"max_bin\": 512})\n",
    "val_data_sel   = lgb.Dataset(X_val_sel, label=y_val, params={\"max_bin\": 512})\n",
    "\n",
    "print(\"\\n[phase 2] Training model with selected features...\")\n",
    "\n",
    "model_sel = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data_sel,\n",
    "    valid_sets=[train_data_sel, val_data_sel],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=900,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "171f4426-c798-4a52-ba01-6f48b26bf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation Results ===\n",
      "LogLoss: 0.15397\n",
      "AP: 0.06940\n",
      "Weighted Score (lower is better): 0.54228\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 9️⃣ Validation Evaluation\n",
    "# -----------------------------------------------\n",
    "y_val_pred = model_sel.predict(X_val_sel)\n",
    "val_logloss = log_loss(y_val, y_val_pred)\n",
    "val_ap = average_precision_score(y_val, y_val_pred)\n",
    "weighted_score = 0.5 * (1 - val_ap) + 0.5 * val_logloss\n",
    "\n",
    "print(f\"\\n=== Validation Results ===\")\n",
    "print(f\"LogLoss: {val_logloss:.5f}\")\n",
    "print(f\"AP: {val_ap:.5f}\")\n",
    "print(f\"Weighted Score (lower is better): {weighted_score:.5f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6561af-87c5-48cd-b1c6-9629dfd154dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model_sel.predict(X_val_sel)\n",
    "from sklearn.metrics import log_loss, average_precision_score\n",
    "val_logloss = log_loss(y_val, y_val_pred)\n",
    "val_ap = average_precision_score(y_val, y_val_pred)\n",
    "weighted_score = 0.5 * (1 - val_ap) + 0.5 * val_logloss\n",
    "\n",
    "print(f\"\\n[Validation]\")\n",
    "print(f\"LogLoss: {val_logloss:.5f}\")\n",
    "print(f\"AP: {val_ap:.5f}\")\n",
    "print(f\"Weighted Score (lower is better): {weighted_score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331c804-dbfd-436c-832e-83b995916f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts(normalize=True))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_val_pred, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bddab6-bc69-43fb-8d38-bf21afb9d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 🔟 Submission CSV Generation\n",
    "# -----------------------------------------------\n",
    "y_test_pred = model_sel.predict(X_test_sel, num_iteration=model_sel.best_iteration)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"id\"],      # test에는 소문자 id 존재\n",
    "    \"clicked\": y_test_pred\n",
    "}).sort_values(\"ID\").reset_index(drop=True)\n",
    "\n",
    "submission_path = \"toss_lgbm_v6_submit.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"[info] Saved submission file → {submission_path}\")\n",
    "print(submission.head())\n",
    "\n",
    "# -----------------------------------------------\n",
    "# ✅ Sanity Check\n",
    "# -----------------------------------------------\n",
    "print(\"\\n[check] submission sanity check\")\n",
    "print(f\"- ID duplicates: {submission['ID'].duplicated().sum()}\")\n",
    "print(f\"- clicked missing: {submission['clicked'].isna().sum()}\")\n",
    "print(f\"- clicked range: {submission['clicked'].min():.4f} ~ {submission['clicked'].max():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
