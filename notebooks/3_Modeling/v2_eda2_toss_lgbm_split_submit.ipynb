{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce8d931-42d6-4cb7-bab0-38550b2b39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR - LGBM + Feature Selection (Exclude Support)\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, average_precision_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f931b5f-d16e-49d1-8c84-1e9c6f5aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 1ï¸âƒ£ Load data\n",
    "# -----------------------------------------------\n",
    "train = pd.read_parquet(\"train_input_2.parquet\")\n",
    "test  = pd.read_parquet(\"test_input_2.parquet\")\n",
    "\n",
    "target_col = \"clicked\"\n",
    "id_col = \"row_id\" if \"row_id\" in train.columns else \"ID\"\n",
    "\n",
    "X = train.drop(columns=[target_col, id_col])\n",
    "y = train[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bd8b2f-148f-4467-9393-80ac8de29a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# 2ï¸âƒ£ ì œì™¸í•  í”¼ì²˜ ì§€ì • (í•„ìš” ì‹œ ì´ë¦„ë§Œ ì¶”ê°€)\n",
    "# -----------------------------------------------\n",
    "exclude_features = [\n",
    "    # ì˜ˆì‹œ: \"diversity_ratio\", \"feat_e_3\", \"user_cluster\"\n",
    "]\n",
    "if exclude_features:\n",
    "    print(f\"[info] Excluding {len(exclude_features)} features: {exclude_features}\")\n",
    "    X = X.drop(columns=[f for f in exclude_features if f in X.columns], errors=\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6012b0f5-c214-46da-a4f0-6f367afff0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] scale_pos_weight = 51.43\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 3ï¸âƒ£ Train/Valid split\n",
    "# -----------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4ï¸âƒ£ scale_pos_weight (Weighted LogLoss)\n",
    "# -----------------------------------------------\n",
    "pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "print(f\"[info] scale_pos_weight = {pos_weight:.2f}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data   = lgb.Dataset(X_val, label=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3650a8e-cf9c-4f0f-8ec6-ab656ec8cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's binary_logloss: 0.601335\tvalid's binary_logloss: 0.601849\n",
      "[200]\ttrain's binary_logloss: 0.602734\tvalid's binary_logloss: 0.603505\n",
      "[300]\ttrain's binary_logloss: 0.600408\tvalid's binary_logloss: 0.601407\n",
      "[400]\ttrain's binary_logloss: 0.597291\tvalid's binary_logloss: 0.598513\n",
      "[500]\ttrain's binary_logloss: 0.594644\tvalid's binary_logloss: 0.596094\n",
      "[600]\ttrain's binary_logloss: 0.591818\tvalid's binary_logloss: 0.593499\n",
      "[700]\ttrain's binary_logloss: 0.589164\tvalid's binary_logloss: 0.591067\n",
      "[800]\ttrain's binary_logloss: 0.586858\tvalid's binary_logloss: 0.588999\n",
      "[900]\ttrain's binary_logloss: 0.58451\tvalid's binary_logloss: 0.586864\n",
      "[1000]\ttrain's binary_logloss: 0.582025\tvalid's binary_logloss: 0.584586\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# -----------------------------------------------\n",
    "# 5ï¸âƒ£ LightGBM Parameters\n",
    "# -----------------------------------------------\n",
    "train_data = lgb.Dataset(X_train, label=y_train, params={\"max_bin\": 512})\n",
    "val_data   = lgb.Dataset(X_val, label=y_val, params={\"max_bin\": 512})\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.05,          # ì™„ë§Œí•œ í•™ìŠµ\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"scale_pos_weight\": pos_weight, # ìœ ì§€\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "    \"n_jobs\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 6ï¸âƒ£ Train (early stopping ì œê±°)\n",
    "# -----------------------------------------------\n",
    "callbacks = [lgb.log_evaluation(period=100)]\n",
    "\n",
    "model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70323669-3217-4a9c-b398-402357e2a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Initially selected 11 features out of 26 total.\n",
      "[info] After removing highly correlated ones (>0.9): 10 remain.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 7ï¸âƒ£ Feature Importance ê¸°ë°˜ Selection (ê°œì„  ë²„ì „)\n",
    "# -----------------------------------------------\n",
    "imp = pd.DataFrame({\n",
    "    \"feature\": model.feature_name(),\n",
    "    \"importance\": model.feature_importance(importance_type=\"gain\")\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "imp[\"norm_imp\"] = imp[\"importance\"] / imp[\"importance\"].sum()\n",
    "imp[\"cum_ratio\"] = imp[\"norm_imp\"].cumsum()\n",
    "\n",
    "selected_features = imp.loc[imp[\"cum_ratio\"] <= 0.95, \"feature\"].tolist()\n",
    "print(f\"[info] Initially selected {len(selected_features)} features out of {X.shape[1]} total.\")\n",
    "\n",
    "corr_matrix = X[selected_features].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "selected_features = [f for f in selected_features if f not in high_corr_features]\n",
    "print(f\"[info] After removing highly correlated ones (>0.9): {len(selected_features)} remain.\")\n",
    "\n",
    "imp.to_csv(\"feature_importance_full.csv\", index=False)\n",
    "pd.Series(selected_features, name=\"selected_features\").to_csv(\"selected_features_v2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e878fa-5a4e-4852-8eb8-422869147a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[phase 2] Training model with selected features...\n",
      "[100]\ttrain's binary_logloss: 0.602629\tvalid's binary_logloss: 0.603079\n",
      "[200]\ttrain's binary_logloss: 0.604077\tvalid's binary_logloss: 0.604794\n",
      "[300]\ttrain's binary_logloss: 0.601922\tvalid's binary_logloss: 0.602876\n",
      "[400]\ttrain's binary_logloss: 0.598955\tvalid's binary_logloss: 0.600122\n",
      "[500]\ttrain's binary_logloss: 0.596442\tvalid's binary_logloss: 0.597819\n",
      "[600]\ttrain's binary_logloss: 0.593793\tvalid's binary_logloss: 0.595392\n",
      "[700]\ttrain's binary_logloss: 0.591272\tvalid's binary_logloss: 0.593092\n",
      "[800]\ttrain's binary_logloss: 0.589121\tvalid's binary_logloss: 0.591154\n",
      "[900]\ttrain's binary_logloss: 0.586906\tvalid's binary_logloss: 0.589121\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 8ï¸âƒ£ Retrain with selected features\n",
    "# -----------------------------------------------\n",
    "X_test = test.drop(columns=[col for col in [\"clicked\", \"ID\", \"row_id\"] if col in test.columns], errors=\"ignore\")\n",
    "\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_val_sel   = X_val[selected_features]\n",
    "X_test_sel  = X_test[selected_features]\n",
    "\n",
    "train_data_sel = lgb.Dataset(X_train_sel, label=y_train, params={\"max_bin\": 512})\n",
    "val_data_sel   = lgb.Dataset(X_val_sel, label=y_val, params={\"max_bin\": 512})\n",
    "\n",
    "params_sel = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"scale_pos_weight\": pos_weight,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"min_gain_to_split\": 0.0,\n",
    "    \"n_jobs\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "print(\"\\n[phase 2] Training model with selected features...\")\n",
    "callbacks = [lgb.log_evaluation(period=100)]\n",
    "\n",
    "model_sel = lgb.train(\n",
    "    params=params_sel,\n",
    "    train_set=train_data_sel,\n",
    "    valid_sets=[train_data_sel, val_data_sel],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=900,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9da4e1f-b4b9-4a71-8598-c2b9161b8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation Results ===\n",
      "LogLoss: 0.58912\n",
      "AP: 0.06871\n",
      "Weighted Score (lower is better): 0.76021\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# 9ï¸âƒ£ Validation Evaluation\n",
    "# -----------------------------------------------\n",
    "\n",
    "y_val_pred = model_sel.predict(X_val_sel)\n",
    "val_logloss = log_loss(y_val, y_val_pred)\n",
    "val_ap = average_precision_score(y_val, y_val_pred)\n",
    "weighted_score = 0.5 * (1 - val_ap) + 0.5 * val_logloss\n",
    "\n",
    "print(f\"\\n=== Validation Results ===\")\n",
    "print(f\"LogLoss: {val_logloss:.5f}\")\n",
    "print(f\"AP: {val_ap:.5f}\")\n",
    "print(f\"Weighted Score (lower is better): {weighted_score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a103c05-9240-443a-a5c0-9d97ec3f6c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved submission file â†’ toss_lgbm_v2_submit.csv\n",
      "             ID   clicked\n",
      "0  TEST_0000000  0.433195\n",
      "1  TEST_0000001  0.369427\n",
      "2  TEST_0000002  0.402421\n",
      "3  TEST_0000003  0.325831\n",
      "4  TEST_0000004  0.348539\n",
      "\n",
      "[check] submission sanity check\n",
      "- ID ì¤‘ë³µ ì—¬ë¶€: 0 duplicates\n",
      "- clicked ê²°ì¸¡ì¹˜ ì—¬ë¶€: 0 missing\n",
      "- clicked ê°’ ë²”ìœ„: 0.0091 ~ 0.9909\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ğŸ”Ÿ Submission CSV Generation (Final for lowercase 'id')\n",
    "# -----------------------------------------------\n",
    "\n",
    "# test ë°ì´í„° í™•ì¸\n",
    "assert \"id\" in test.columns, \"[error] test ë°ì´í„°ì— 'id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì˜ˆì¸¡ í™•ë¥  ìƒì„±\n",
    "y_test_pred = model_sel.predict(X_test_sel, num_iteration=model_sel.best_iteration)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„± (id + clicked)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"id\"],        # âœ… testì—ëŠ” ì†Œë¬¸ì 'id' ì‚¬ìš©\n",
    "    \"clicked\": y_test_pred\n",
    "}).sort_values(\"ID\").reset_index(drop=True)\n",
    "\n",
    "# ì €ì¥\n",
    "submission_path = \"toss_lgbm_v2_submit.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"[info] Saved submission file â†’ {submission_path}\")\n",
    "print(submission.head())\n",
    "\n",
    "# -----------------------------------------------\n",
    "# âœ… sanity check (ê¶Œì¥)\n",
    "# -----------------------------------------------\n",
    "print(\"\\n[check] submission sanity check\")\n",
    "print(f\"- ID ì¤‘ë³µ ì—¬ë¶€: {submission['ID'].duplicated().sum()} duplicates\")\n",
    "print(f\"- clicked ê²°ì¸¡ì¹˜ ì—¬ë¶€: {submission['clicked'].isna().sum()} missing\")\n",
    "print(f\"- clicked ê°’ ë²”ìœ„: {submission['clicked'].min():.4f} ~ {submission['clicked'].max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c772af2-eaac-47c4-a02d-442c4b0022d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
