{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0501c545-b9f1-461e-b91a-938cfb69a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR — XGBoost v3 (Feature-Selection → CV → Submit)\n",
    "# Author: 람쥐\n",
    "# Notes:\n",
    "# - Input files: train_input_2.parquet, test_input_2.parquet (already EDA & Preprocessing done)\n",
    "# - Train-only fit for feature selection; then apply same selected columns to test\n",
    "# - CV metric matches competition: 0.5*AP + 0.5*(1/(1+WeightedLogLoss))\n",
    "# - Final submission: toss_xgb_v3_submit.csv with columns [ID, clicked]\n",
    "# ===============================================\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6403df45-338d-475d-969b-e27d2648c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# -----------------------------------------------\n",
    "TRAIN_PATH = './train_input_2.parquet'\n",
    "TEST_PATH  = './test_input_2.parquet'\n",
    "SUBMIT_PATH = './toss_xgb_v3_submit.csv'\n",
    "FEATURES_PATH = './xgb_v3_selected_features.txt'\n",
    "MODEL_PATH = './xgb_v3_model.json'\n",
    "LOG_PATH = './xgb_v3_log.txt'\n",
    "\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "EARLY_STOPPING_ROUNDS = 30\n",
    "MAX_BOOST_ROUNDS = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78beff88-a3df-4f4e-9f39-0ef227c91401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Utils\n",
    "# -----------------------------------------------\n",
    "def weighted_logloss(y_true, y_pred, eps=1e-15):\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    mask0 = (y_true == 0)\n",
    "    mask1 = (y_true == 1)\n",
    "    ll0 = -np.mean(np.log(1 - y_pred[mask0])) if mask0.sum() else 0.0\n",
    "    ll1 = -np.mean(np.log(y_pred[mask1])) if mask1.sum() else 0.0\n",
    "    return 0.5 * ll0 + 0.5 * ll1\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    wll = weighted_logloss(y_true, y_pred)\n",
    "    score = 0.5 * ap + 0.5 * (1.0 / (1.0 + wll))\n",
    "    return score, ap, wll\n",
    "\n",
    "\n",
    "def detect_tree_method():\n",
    "    try:\n",
    "        # Try a tiny GPU booster to check availability\n",
    "        _ = xgb.Booster(params={'tree_method': 'gpu_hist'})\n",
    "        return 'gpu_hist'\n",
    "    except Exception:\n",
    "        return 'hist'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf27695-9127-41c3-a433-b9f7a98e5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Loading parquet files...\n",
      "[info] Train shape: (10704168, 28), Test shape: (1527298, 27)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Load\n",
    "# -----------------------------------------------\n",
    "print(\"[info] Loading parquet files...\")\n",
    "train = pd.read_parquet(TRAIN_PATH)\n",
    "_test = pd.read_parquet(TEST_PATH)\n",
    "print(f\"[info] Train shape: {train.shape}, Test shape: {_test.shape}\")\n",
    "\n",
    "assert 'clicked' in train.columns, \"Target column 'clicked' not found in train_input_2.parquet\"\n",
    "\n",
    "# Keep original test ID for submission\n",
    "if 'ID' in _test.columns:\n",
    "    test_id = _test['ID'].astype(str).copy()\n",
    "elif 'id' in _test.columns:\n",
    "    test_id = _test['id'].astype(str).copy()\n",
    "else:\n",
    "    # Fallback synthetic ID\n",
    "    test_id = pd.Series([f\"TEST_{i:07d}\" for i in range(len(_test))], name='ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1a965c-1ef6-455e-ab76-9422ce5b8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[check] Aligned columns. Train features: 27, Test features: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------\n",
    "# Split X, y\n",
    "# -----------------------------------------------\n",
    "TARGET_COL = 'clicked'\n",
    "y = train[TARGET_COL].astype(np.int8).values\n",
    "X = train.drop(columns=[TARGET_COL])\n",
    "X_test = _test.copy()\n",
    "\n",
    "# Downcast to float32 where possible\n",
    "for df in (X, X_test):\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'float64':\n",
    "            df[c] = df[c].astype('float32')\n",
    "        elif str(df[c].dtype).startswith('int'):\n",
    "            df[c] = df[c].astype('int32')\n",
    "\n",
    "# Align train/test columns now (pre-selection)\n",
    "missing_in_test = [c for c in X.columns if c not in X_test.columns]\n",
    "extra_in_test = [c for c in X_test.columns if c not in X.columns]\n",
    "\n",
    "if missing_in_test:\n",
    "    for c in missing_in_test:\n",
    "        X_test[c] = 0\n",
    "if extra_in_test:\n",
    "    X_test = X_test.drop(columns=extra_in_test)\n",
    "\n",
    "X_test = X_test[X.columns]\n",
    "print(f\"[check] Aligned columns. Train features: {X.shape[1]}, Test features: {X_test.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d901ca-0b4e-447a-b96e-64388cc99df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Positive ratio: 0.019075, scale_pos_weight: 51.425\n"
     ]
    }
   ],
   "source": [
    "# Scale pos weight (class imbalance)\n",
    "# -----------------------------------------------\n",
    "pos_ratio = float(np.mean(y))\n",
    "scale_pos_weight = (1.0 - pos_ratio) / pos_ratio if pos_ratio > 0 else 1.0\n",
    "print(f\"[info] Positive ratio: {pos_ratio:.6f}, scale_pos_weight: {scale_pos_weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802fbd57-78fc-4575-bb5c-a0155edefdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] Feature selection fit on train only\n",
      "[info] device: cuda, tree_method: hist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml_project/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:52:36] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/conda/envs/ml_project/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:52:36] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Selected 14 / 27 features → saved to ./xgb_v3_selected_features.txt\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection (train only)\n",
    "# -----------------------------------------------\n",
    "print(\"[step] Feature selection fit on train only\")\n",
    "\n",
    "# detect_tree_method() 함수가 'gpu_hist'를 반환해도\n",
    "# XGBoost 2.x에서는 tree_method='hist', device='cuda'로 써야 함\n",
    "tree_method = \"hist\"\n",
    "device_type = \"cuda\"  # GPU 사용 환경\n",
    "# device_type = \"cpu\"  # GPU 없을 경우엔 이렇게 바꿔주면 됨\n",
    "\n",
    "print(f\"[info] device: {device_type}, tree_method: {tree_method}\")\n",
    "\n",
    "selector_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=tree_method,\n",
    "    device=device_type,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "selector_model.fit(X, y)\n",
    "\n",
    "selector = SelectFromModel(selector_model, prefit=True, threshold='median')\n",
    "mask = selector.get_support()\n",
    "selected_features = X.columns[mask].tolist()\n",
    "\n",
    "with open(FEATURES_PATH, 'w', encoding='utf-8') as f:\n",
    "    for ftr in selected_features:\n",
    "        f.write(ftr + \"\\n\")\n",
    "print(f\"[info] Selected {len(selected_features)} / {X.shape[1]} features → saved to {FEATURES_PATH}\")\n",
    "\n",
    "# Reduce to selected features\n",
    "X_sel = X[selected_features].copy()\n",
    "X_test_sel = X_test[selected_features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0bd2ac-ce4a-4145-81f5-efb7ffd566b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] Stratified KFold CV\n",
      "[fold 1] train=8,563,334, valid=2,140,834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml_project/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:54:56] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/conda/envs/ml_project/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:54:56] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/conda/envs/ml_project/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [17:54:56] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 1] score=0.344284 | AP=0.069632 | WLL=0.615677 | best_iter=499\n",
      "[fold 2] train=8,563,334, valid=2,140,834\n",
      "[fold 2] score=0.344149 | AP=0.068936 | WLL=0.614563 | best_iter=499\n",
      "[fold 3] train=8,563,334, valid=2,140,834\n",
      "[fold 3] score=0.343590 | AP=0.068132 | WLL=0.615386 | best_iter=499\n",
      "[fold 4] train=8,563,335, valid=2,140,833\n",
      "[fold 4] score=0.344392 | AP=0.069420 | WLL=0.614559 | best_iter=499\n",
      "[fold 5] train=8,563,335, valid=2,140,833\n",
      "[fold 5] score=0.344777 | AP=0.070538 | WLL=0.615468 | best_iter=499\n",
      "[cv] score=0.344238 ± 0.000386 | AP=0.069332 | WLL=0.615131\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Cross-Validation\n",
    "# -----------------------------------------------\n",
    "print(\"[step] Stratified KFold CV\")\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': tree_method,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.025,\n",
    "    'subsample': 0.75,\n",
    "    'colsample_bytree': 0.65,\n",
    "    'reg_lambda': 2.0,\n",
    "    'min_child_weight': 8,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'gpu_id': 0,\n",
    "    'verbosity': 0,\n",
    "    'seed': RANDOM_STATE,\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores, cv_ap, cv_wll, best_iters = [], [], [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_sel, y), 1):\n",
    "    print(f\"[fold {fold}] train={len(tr_idx):,}, valid={len(va_idx):,}\")\n",
    "    X_tr, X_va = X_sel.iloc[tr_idx], X_sel.iloc[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dvalid = xgb.DMatrix(X_va, label=y_va)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=MAX_BOOST_ROUNDS,\n",
    "        evals=[(dvalid, 'valid')],\n",
    "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_hat = booster.predict(dvalid)\n",
    "    score, ap, wll = competition_score(y_va, y_hat)\n",
    "    cv_scores.append(score)\n",
    "    cv_ap.append(ap)\n",
    "    cv_wll.append(wll)\n",
    "    best_iters.append(booster.best_iteration)\n",
    "\n",
    "    print(f\"[fold {fold}] score={score:.6f} | AP={ap:.6f} | WLL={wll:.6f} | best_iter={booster.best_iteration}\")\n",
    "\n",
    "    del dtrain, dvalid, booster, X_tr, X_va, y_tr, y_va, y_hat\n",
    "    gc.collect()\n",
    "\n",
    "print(\"[cv] score=%.6f ± %.6f | AP=%.6f | WLL=%.6f\" % (\n",
    "    np.mean(cv_scores), np.std(cv_scores), np.mean(cv_ap), np.mean(cv_wll)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba99b769-2c47-42b2-857f-9eb60542d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] Train final model on full train with selected features\n",
      "[info] Using num_boost_round=499\n",
      "[info] Saved model to ./xgb_v3_model.json\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# Train final model on full data\n",
    "# -----------------------------------------------\n",
    "print(\"[step] Train final model on full train with selected features\")\n",
    "final_rounds = int(np.mean(best_iters)) if best_iters else MAX_BOOST_ROUNDS\n",
    "final_rounds = max(final_rounds, 50)\n",
    "print(f\"[info] Using num_boost_round={final_rounds}\")\n",
    "\n",
    "D_full = xgb.DMatrix(X_sel, label=y)\n",
    "final_booster = xgb.train(\n",
    "    params,\n",
    "    D_full,\n",
    "    num_boost_round=final_rounds,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "final_booster.save_model(MODEL_PATH)\n",
    "print(f\"[info] Saved model to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf0f4c1-d3f4-46bf-ad39-cbaf672f87c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step] Inference on test_input_2\n",
      "[save] Submission saved → ./toss_xgb_v3_submit.csv\n"
     ]
    }
   ],
   "source": [
    "# Inference on test\n",
    "# -----------------------------------------------\n",
    "print(\"[step] Inference on test_input_2\")\n",
    "D_test = xgb.DMatrix(X_test_sel)\n",
    "proba = final_booster.predict(D_test)\n",
    "\n",
    "\n",
    "# Clipping for safety\n",
    "proba = np.clip(proba, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# Build submission\n",
    "submit = pd.DataFrame({\n",
    "'ID': test_id.values,\n",
    "'clicked': proba\n",
    "})\n",
    "\n",
    "\n",
    "# Ensure correct dtypes and ordering\n",
    "submit['ID'] = submit['ID'].astype(str)\n",
    "submit = submit[['ID', 'clicked']]\n",
    "\n",
    "\n",
    "submit.to_csv(SUBMIT_PATH, index=False)\n",
    "print(f\"[save] Submission saved → {SUBMIT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1e0a2b-6d32-43c1-a18d-9a9dd9d3e53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[check] Submission preview:\n",
      "             ID   clicked\n",
      "0  TEST_0000000  0.344309\n",
      "1  TEST_0000001  0.383575\n",
      "2  TEST_0000002  0.453257\n",
      "3  TEST_0000003  0.380793\n",
      "4  TEST_0000004  0.279646\n",
      "[check] Range of clicked: 0.0091 ~ 0.9934\n",
      "[done] XGBoost v3 pipeline complete\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks and logging\n",
    "# -----------------------------------------------\n",
    "print(\"[check] Submission preview:\")\n",
    "print(submit.head())\n",
    "print(\"[check] Range of clicked: %.4f ~ %.4f\" % (submit['clicked'].min(), submit['clicked'].max()))\n",
    "\n",
    "\n",
    "with open(LOG_PATH, 'a', encoding='utf-8') as f:\n",
    " f.write(\n",
    " f\"{datetime.now()} | score={np.mean(cv_scores):.6f}±{np.std(cv_scores):.6f} | \"\n",
    " f\"AP={np.mean(cv_ap):.6f} | WLL={np.mean(cv_wll):.6f} | \"\n",
    " f\"features={len(selected_features)} | rounds={final_rounds} | tree_method={tree_method}\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"[done] XGBoost v3 pipeline complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd05b0-2da0-4158-be07-7a5e82fdce84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
