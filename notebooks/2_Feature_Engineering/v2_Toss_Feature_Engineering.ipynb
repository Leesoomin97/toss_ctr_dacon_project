{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4884c69-56bd-4053-9166-7373973ff2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Toss CTR - Feature Engineering & Selection (Phase 2)\n",
    "# ===============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a9eb86-a6e4-4d53-8749-40a4318822ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading data...\n",
      "train shape: (10704168, 134), test shape: (1527298, 133)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================================\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "# ===============================================\n",
    "print(\"üì¶ Loading data...\")\n",
    "train = pd.read_parquet(\"train_basic_2.parquet\")\n",
    "test  = pd.read_parquet(\"test_basic_2.parquet\")\n",
    "\n",
    "if \"ID\" in test.columns:\n",
    "    test.rename(columns={\"ID\": \"id\"}, inplace=True)\n",
    "\n",
    "if \"id\" not in train.columns:\n",
    "    train[\"row_id\"] = np.arange(len(train))\n",
    "    id_col = \"row_id\"\n",
    "else:\n",
    "    id_col = \"id\"\n",
    "\n",
    "target_col = \"clicked\" if \"clicked\" in train.columns else None\n",
    "\n",
    "print(f\"train shape: {train.shape}, test shape: {test.shape}\")\n",
    "\n",
    "y_col = \"clicked\"\n",
    "id_cols = [c for c in [\"row_id\", \"id\", \"index\"] if c in train.columns or c in test.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14578a0f-fdba-4407-83ef-f2179186673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID, target Î≥¥Ï°¥Ïö© Î≤†Ïù¥Ïä§ÌîÑÎ†àÏûÑ\n",
    "out_train_df = pd.DataFrame(index=train.index)\n",
    "out_test_df  = pd.DataFrame(index=test.index)\n",
    "\n",
    "for c in id_cols:\n",
    "    if c in train.columns:\n",
    "        out_train_df[c] = train[c]\n",
    "    if c in test.columns:\n",
    "        out_test_df[c] = test[c]\n",
    "if y_col in train.columns:\n",
    "    out_train_df[y_col] = train[y_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acee62d6-661f-4103-beec-b956e8600a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 2. Í∏∞Î≥∏ Ïù∏ÏΩîÎî© + ÏÇ¨Ïù¥ÌÅ¥Î¶≠ Ïù∏ÏΩîÎî©\n",
    "# ===============================================\n",
    "def cyclic_encode(series, period, prefix):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").fillna(0) % period\n",
    "    return pd.DataFrame({\n",
    "        f\"{prefix}_sin\": np.sin(2 * np.pi * s / period),\n",
    "        f\"{prefix}_cos\": np.cos(2 * np.pi * s / period)\n",
    "    }, index=series.index)\n",
    "\n",
    "# Label Encoding\n",
    "for col in [\"gender\", \"age_group\", \"user_cluster\"]:\n",
    "    if col in train.columns and col in test.columns:\n",
    "        le = LabelEncoder()\n",
    "        both = pd.concat([train[col].astype(str), test[col].astype(str)], axis=0)\n",
    "        le.fit(both.fillna(\"nan\"))\n",
    "        out_train_df[col] = le.transform(train[col].astype(str).fillna(\"nan\"))\n",
    "        out_test_df[col]  = le.transform(test[col].astype(str).fillna(\"nan\"))\n",
    "\n",
    "# Cyclic features\n",
    "if \"hour\" in train.columns:\n",
    "    out_train_df = pd.concat([out_train_df, cyclic_encode(train[\"hour\"], 24, \"hour\")], axis=1)\n",
    "    out_test_df  = pd.concat([out_test_df, cyclic_encode(test[\"hour\"], 24, \"hour\")], axis=1)\n",
    "if \"day_of_week\" in train.columns:\n",
    "    out_train_df = pd.concat([out_train_df, cyclic_encode(train[\"day_of_week\"], 7, \"dow\")], axis=1)\n",
    "    out_test_df  = pd.concat([out_test_df, cyclic_encode(test[\"day_of_week\"], 7, \"dow\")], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047c8357-6fe5-498f-be49-282d32ecd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# 3. Sequence Features (Ïù¥ÎØ∏ Ï†ÑÏ≤òÎ¶¨ÏóêÏÑú ÏÉùÏÑ±Îê®)\n",
    "# ===============================================\n",
    "for col in [\"seq_length\", \"seq_length_log\"]:\n",
    "    if col in train.columns:\n",
    "        out_train_df[col] = train[col]\n",
    "        out_test_df[col]  = test[col]\n",
    "\n",
    "# ===============================================\n",
    "# 4. History Features\n",
    "# ===============================================\n",
    "hist_cols = [\n",
    "    \"history_mean\", \"history_var\", \"history_a_mean\", \"history_b_mean\",\n",
    "    \"history_clicked_corr\", \"history_a_1\", \"history_b_2\"\n",
    "]\n",
    "for col in hist_cols:\n",
    "    if col in train.columns and col in test.columns:\n",
    "        out_train_df[col] = train[col]\n",
    "        out_test_df[col]  = test[col]\n",
    "    elif col in train.columns:\n",
    "        out_train_df[col] = train[col]\n",
    "        out_test_df[col]  = 0\n",
    "    elif col in test.columns:\n",
    "        out_train_df[col] = 0\n",
    "        out_test_df[col]  = test[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b92f843-b505-42ca-9590-fa387bf5ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================================\n",
    "# 5. CTR & Cross Feature\n",
    "# ===============================================\n",
    "def has_cols(df, cols): return all(c in df.columns for c in cols)\n",
    "\n",
    "def frequency_encode(train_s, test_s):\n",
    "    freq = train_s.value_counts(dropna=False) / len(train_s)\n",
    "    return train_s.map(freq).astype(float), test_s.map(freq).astype(float)\n",
    "\n",
    "def mean_target_encode(trn_cat, trn_y, tst_cat, global_mean=None, min_samples_leaf=50, smoothing=10.0):\n",
    "    if global_mean is None:\n",
    "        global_mean = trn_y.mean() if len(trn_y) else 0.0\n",
    "    stats = pd.DataFrame({\"cat\": trn_cat, \"y\": trn_y}).groupby(\"cat\")[\"y\"].agg([\"mean\", \"count\"])\n",
    "    smoothing_factor = 1 / (1 + np.exp(-(stats[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    stats[\"enc\"] = global_mean * (1 - smoothing_factor) + stats[\"mean\"] * smoothing_factor\n",
    "    trn_enc = trn_cat.map(stats[\"enc\"]).fillna(global_mean)\n",
    "    tst_enc = tst_cat.map(stats[\"enc\"]).fillna(global_mean)\n",
    "    return trn_enc, tst_enc\n",
    "\n",
    "def safe_te_or_fe(train_df, test_df, cat_col, y_col=\"clicked\"):\n",
    "    if y_col not in train_df or train_df[y_col].nunique() < 2:\n",
    "        return frequency_encode(train_df[cat_col], test_df[cat_col])\n",
    "    try:\n",
    "        trn, tst = mean_target_encode(train_df[cat_col], train_df[y_col], test_df[cat_col])\n",
    "        if trn.std() < 1e-10:\n",
    "            return frequency_encode(train_df[cat_col], test_df[cat_col])\n",
    "        return trn, tst\n",
    "    except:\n",
    "        return frequency_encode(train_df[cat_col], test_df[cat_col])\n",
    "\n",
    "# Í∏∞Î≥∏ CTR columns\n",
    "ctr_cols = [\"click_ratio_per_age\", \"click_ratio_per_hour\", \"click_ratio_per_dow\", \"inventory_ctr\"]\n",
    "for col in ctr_cols:\n",
    "    if col in train.columns:\n",
    "        out_train_df[col] = train[col]\n",
    "        out_test_df[col]  = test[col]\n",
    "\n",
    "# Ï£ºÏöî ÍµêÏ∞® feature\n",
    "crosses = [\n",
    "    (\"hour_dow_cross\", [\"hour\", \"day_of_week\"]),\n",
    "    (\"age_gender_cross\", [\"age_group\", \"gender\"]),\n",
    "    (\"inventory_id_hour_cross\", [\"inventory_id\", \"hour\"])\n",
    "]\n",
    "for name, cols in crosses:\n",
    "    if has_cols(train, cols):\n",
    "        tr_cat = train[cols].astype(str).fillna(\"nan\").agg(\"|\".join, axis=1)\n",
    "        ts_cat = test[cols].astype(str).fillna(\"nan\").agg(\"|\".join, axis=1)\n",
    "        tmp_train = pd.DataFrame({\"tmp\": tr_cat, \"clicked\": train[y_col]})\n",
    "        tmp_test = pd.DataFrame({\"tmp\": ts_cat})\n",
    "        tr_enc, ts_enc = safe_te_or_fe(tmp_train, tmp_test, \"tmp\", y_col)\n",
    "        out_train_df[name] = tr_enc\n",
    "        out_test_df[name]  = ts_enc\n",
    "\n",
    "# inventory_id Ïù∏ÏΩîÎî©\n",
    "if \"inventory_id\" in train.columns:\n",
    "    tr_te, ts_te = safe_te_or_fe(train, test, \"inventory_id\", y_col)\n",
    "    tr_fe, ts_fe = frequency_encode(train[\"inventory_id\"], test[\"inventory_id\"])\n",
    "    out_train_df[\"inventory_id_te\"] = tr_te\n",
    "    out_test_df[\"inventory_id_te\"]  = ts_te\n",
    "    out_train_df[\"inventory_id_fe\"] = tr_fe\n",
    "    out_test_df[\"inventory_id_fe\"]  = ts_fe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4599ef87-ccae-4acb-975d-a8a66241938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================================\n",
    "# 6. Embedding / Flags / Ï∂îÍ∞Ä Feature\n",
    "# ===============================================\n",
    "add_cols = [\n",
    "    \"diversity_ratio\", \"new_user_flag\", \"is_weekend\", \"tuesday_flag\",\n",
    "    \"night_flag\", \"pca_component_1\", \"user_cluster\"\n",
    "]\n",
    "for col in add_cols:\n",
    "    if col in train.columns:\n",
    "        out_train_df[col] = train[col]\n",
    "        out_test_df[col]  = test[col]\n",
    "\n",
    "# ===============================================\n",
    "# 7. Scaling (ÏàòÏπòÌòïÎßå)\n",
    "# ===============================================\n",
    "class StdScalerCols(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols; self.scaler = StandardScaler()\n",
    "    def fit(self, X, y=None):\n",
    "        cols = [c for c in self.cols if c in X.columns]\n",
    "        self.scaler.fit(X[cols]); self.cols = cols; return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy(); X[self.cols] = self.scaler.transform(X[self.cols]); return X\n",
    "\n",
    "num_cols = [c for c in out_train_df.columns if out_train_df[c].dtype != \"object\" and c not in id_cols + [y_col]]\n",
    "scaler = StdScalerCols(num_cols)\n",
    "scaler.fit(out_train_df)\n",
    "out_train_df = scaler.transform(out_train_df)\n",
    "out_test_df  = scaler.transform(out_test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609571bd-7ea7-48a5-a757-27b56de9f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Audit] Required 10 features presence\n",
      " - inventory_id_te          | train: OK | test: OK\n",
      " - history_a_1              | train: OK | test: OK\n",
      " - history_b_2              | train: OK | test: OK\n",
      " - seq_length               | train: OK | test: OK\n",
      " - diversity_ratio          | train: OK | test: OK\n",
      " - hour_dow_cross           | train: OK | test: OK\n",
      " - age_gender_cross         | train: OK | test: OK\n",
      " - user_cluster             | train: OK | test: OK\n",
      " - inventory_id_hour_cross  | train: OK | test: OK\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 8. Feature Audit (no autocompletion)\n",
    "# ===============================================\n",
    "\n",
    "# Ïö∞ÏÑ†ÏàúÏúÑ 10Í∞ú (ÏöîÍµ¨ÏÇ¨Ìï≠ Í≥†Ï†ï)\n",
    "required = [\n",
    "    \"inventory_id_te\", \"history_a_1\", \"history_b_2\", \"seq_length\",\n",
    "    \"diversity_ratio\", \"hour_dow_cross\", \"age_gender_cross\",\n",
    "     \"user_cluster\", \"inventory_id_hour_cross\"\n",
    "]\n",
    "\n",
    "# Ïª¨Îüº Ï°¥Ïû¨ Ï≤¥ÌÅ¨\n",
    "train_cols = set(out_train_df.columns)\n",
    "test_cols  = set(out_test_df.columns)\n",
    "\n",
    "missing_train = [c for c in required if c not in train_cols]\n",
    "missing_test  = [c for c in required if c not in test_cols]\n",
    "\n",
    "print(\"\\n[Feature Audit] Required 10 features presence\")\n",
    "for c in required:\n",
    "    print(f\" - {c:24s} | train: {'OK' if c in train_cols else 'MISS'} | test: {'OK' if c in test_cols else 'MISS'}\")\n",
    "\n",
    "if missing_train or missing_test:\n",
    "    print(\"\\n[WARN] Missing required features detected (no autocompletion applied).\")\n",
    "    if missing_train: print(\" - Missing in train:\", missing_train)\n",
    "    if missing_test:  print(\" - Missing in test :\", missing_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1376c833-27a9-49ed-91f1-e3eb80a1ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Audit] Saved feature_audit_train.csv  (rows=28)\n",
      "[Feature Audit] Saved feature_audit_test.csv  (rows=27)\n"
     ]
    }
   ],
   "source": [
    "# ÏÉÅÏàò/Ï†ÑÎ∂Ä 0/Í≤∞Ï∏°ÎπÑÏú®/Í≥†Ïú†Í∞í Ïàò Îì± Í∞êÏÇ¨ÏßÄÌëú ÏÉùÏÑ±\n",
    "# ÎåÄÏö©ÎüâÏù¥Î©¥ ÏÉòÌîåÎßÅÏùÑ ÏºúÏÑ∏Ïöî: AUDIT_SAMPLE = 300000  (NoneÏù¥Î©¥ Ï†ÑÏ≤¥)\n",
    "AUDIT_SAMPLE = 30000\n",
    "\n",
    "def build_audit(df, name=\"train\", sample=AUDIT_SAMPLE):\n",
    "    df2 = df if (sample is None or len(df) <= sample) else df.sample(n=sample, random_state=42)\n",
    "    rows = []\n",
    "    for c in df.columns:\n",
    "        s_full = df[c]\n",
    "        s = df2[c]\n",
    "        dtype = str(s_full.dtype)\n",
    "        non_null_ratio = float(s.notna().mean())\n",
    "        nunique = int(s.nunique(dropna=True))\n",
    "        is_num = pd.api.types.is_numeric_dtype(s_full)\n",
    "        zero_ratio = float((s == 0).mean()) if is_num else float(\"nan\")\n",
    "        is_constant = (nunique <= 1)\n",
    "        rows.append([c, dtype, non_null_ratio, nunique, zero_ratio, is_constant])\n",
    "    audit_df = pd.DataFrame(rows, columns=[\"column\", \"dtype\", \"non_null_ratio\", \"nunique\", \"zero_ratio\", \"is_constant\"])\n",
    "    audit_df = audit_df.sort_values([\"is_constant\", \"zero_ratio\", \"non_null_ratio\", \"column\"],\n",
    "                                    ascending=[False, False, True, True])\n",
    "    audit_df.to_csv(f\"feature_audit_{name}.csv\", index=False)\n",
    "    print(f\"[Feature Audit] Saved feature_audit_{name}.csv  (rows={len(audit_df)})\")\n",
    "    return audit_df\n",
    "\n",
    "audit_train = build_audit(out_train_df, \"train\", AUDIT_SAMPLE)\n",
    "audit_test  = build_audit(out_test_df,  \"test\",  AUDIT_SAMPLE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2268dee2-85b3-4f2e-8c77-fbbed560a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Audit] Saved fe_only_columns.csv  (count=9)\n",
      "\n",
      "[OK] ID and clicked are present. No autocompletion applied for features.\n"
     ]
    }
   ],
   "source": [
    "# ÏõêÎ≥∏ Ï†ÑÏ≤òÎ¶¨ Ïª¨Îüº ÎåÄÎπÑ 'FEÎ°ú ÏÉàÎ°ú ÏÉùÍ∏¥' ÏπºÎüº Î™©Î°ù Ï†ÄÏû•\n",
    "# (trainÏùÄ Ï†ÑÏ≤òÎ¶¨ ÏõêÎ≥∏Ïù¥ Ïù¥ÎØ∏ ÏúÑÏóêÏÑú 'train' Î≥ÄÏàòÎ°ú Î°úÎìúÎêòÏñ¥ ÏûàÏùå)\n",
    "base_cols = set(train.columns)  # Ï†ÑÏ≤òÎ¶¨ Í≤∞Í≥ºÏùò ÏõêÎ≥∏ Ïª¨ÎüºÎì§\n",
    "base_cols |= set([c for c in [\"row_id\", \"id\", \"index\", y_col] if c in base_cols or c in out_train_df.columns])\n",
    "\n",
    "fe_only_cols = [c for c in out_train_df.columns if c not in base_cols]\n",
    "pd.DataFrame({\"feature\": fe_only_cols}).to_csv(\"fe_only_columns.csv\", index=False)\n",
    "print(f\"[Feature Audit] Saved fe_only_columns.csv  (count={len(fe_only_cols)})\")\n",
    "\n",
    "# Î¶¨ÎçîÎ≥¥Îìú Ï†úÏ∂úÏóê ÌïÑÏöîÌïú ID / clicked Î≥¥Ïû• Ïó¨Î∂Ä ÏµúÏ¢Ö Ï†êÍ≤Ä(ÏûêÎèô ÏÉùÏÑ± ÏïÑÎãò, Ï°¥Ïû¨ ÌôïÏù∏Îßå)\n",
    "id_present = [c for c in [\"row_id\", \"id\"] if c in out_train_df.columns]\n",
    "if not id_present:\n",
    "    raise ValueError(\"ID column (row_id or id) is missing in out_train_df.\")\n",
    "if y_col not in out_train_df.columns:\n",
    "    raise ValueError(\"Target column 'clicked' is missing in out_train_df.\")\n",
    "\n",
    "print(\"\\n[OK] ID and clicked are present. No autocompletion applied for features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b0d92ba-8361-4ebd-9ce1-c6c4721c9e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_input_2.parquet / test_input_2.parquet\n",
      "train_input cols: 28, test_input cols: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================================\n",
    "# 9. Ï†ÄÏû•\n",
    "# ===============================================\n",
    "out_train_df.to_parquet(\"train_input_2.parquet\", index=False)\n",
    "out_test_df.to_parquet(\"test_input_2.parquet\", index=False)\n",
    "print(\"Saved train_input_2.parquet / test_input_2.parquet\")\n",
    "print(f\"train_input cols: {len(out_train_df.columns)}, test_input cols: {len(out_test_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3255cd-b761-4682-90c0-e8e95ef0f1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "ml_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
